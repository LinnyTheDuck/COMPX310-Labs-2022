{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-30T01:26:58.023744Z","iopub.execute_input":"2022-10-30T01:26:58.024234Z","iopub.status.idle":"2022-10-30T01:26:58.054074Z","shell.execute_reply.started":"2022-10-30T01:26:58.024113Z","shell.execute_reply":"2022-10-30T01:26:58.053198Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/lastlab2022compx310/train.csv\n/kaggle/input/lastlab2022compx310/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Loading the Data","metadata":{}},{"cell_type":"code","source":"train_csv = pd.read_csv(\"/kaggle/input/lastlab2022compx310/train.csv\", na_values=-9999)\ntest_csv = pd.read_csv(\"/kaggle/input/lastlab2022compx310/test.csv\", na_values=-9999)\n#train_csv.info()\n#test_csv.info()\nprint(train_csv.head())\nprint(test_csv.head())","metadata":{"execution":{"iopub.status.busy":"2022-10-30T01:27:17.404356Z","iopub.execute_input":"2022-10-30T01:27:17.404810Z","iopub.status.idle":"2022-10-30T01:27:32.880584Z","shell.execute_reply.started":"2022-10-30T01:27:17.404777Z","shell.execute_reply":"2022-10-30T01:27:32.879256Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"   id   a0    a1   a2   a3   a4   a5   a6   a7   a8  ...  a56  a57  a58  a59  \\\n0   0  5.0   1.0  1.0  0.0  0.0  7.0  5.0  2.0  2.0  ...  1.0  0.0  NaN  1.0   \n1   1  2.0   1.0  2.0  0.0  0.0  1.0  2.0  2.0  2.0  ...  4.0  0.0  1.0  1.0   \n2   2  7.0  11.0  1.0  0.0  0.0  0.0  0.0  1.0  NaN  ...  0.0  0.0  0.0  2.0   \n3   3  7.0   1.0  1.0  3.0  0.0  0.0  0.0  2.0  2.0  ...  0.0  0.0  0.0  2.0   \n4   4  3.0  11.0  1.0  0.0  0.0  2.0  3.0  2.0  2.0  ...  5.0  0.0  1.0  1.0   \n\n   a60  a61   a62  a63  a64  target  \n0  1.0  0.0  10.0  1.0  0.0      c1  \n1  1.0  0.0   8.0  1.0  0.0      c1  \n2  2.0  0.0   4.0  7.0  0.0      c0  \n3  2.0  0.0  10.0  6.0  0.0      c0  \n4  1.0  0.0  11.0  1.0  0.0      c1  \n\n[5 rows x 67 columns]\n        id   a0    a1   a2   a3   a4   a5   a6   a7   a8  ...  a55  a56  a57  \\\n0  1000000  4.0   1.0  7.0  0.0  0.0  1.0  0.0  2.0  2.0  ...  3.0  0.0  0.0   \n1  1000001  6.0  11.0  1.0  0.0  0.0  6.0  0.0  2.0  2.0  ...  3.0  0.0  0.0   \n2  1000002  4.0   9.0  1.0  0.0  4.0  1.0  3.0  2.0  2.0  ...  0.0  3.0  0.0   \n3  1000003  4.0   1.0  1.0  0.0  0.0  2.0  4.0  2.0  2.0  ...  0.0  3.0  0.0   \n4  1000004  3.0   1.0  1.0  0.0  0.0  4.0  3.0  2.0  2.0  ...  0.0  5.0  0.0   \n\n   a58  a59  a60  a61   a62  a63  a64  \n0  0.0  2.0  2.0  0.0  10.0  4.0  0.0  \n1  1.0  1.0  2.0  1.0  11.0  2.0  2.0  \n2  1.0  1.0  1.0  0.0  15.0  1.0  0.0  \n3  2.0  1.0  NaN  0.0  14.0  1.0  0.0  \n4  1.0  1.0  1.0  0.0  14.0  1.0  0.0  \n\n[5 rows x 66 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# import libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\n\nmy_ID = 1506427\n\nscaler = StandardScaler()\nimputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent') #'median' for everything except xgboost\n\n# drop id and target\nX_train = train_csv.drop(['id','target'], axis = 1)\n\n# drop target for y_train\ny_train_val = np.unique(train_csv['target'], return_inverse = True)[1].tolist()\n\n# drop id or test data\ntest_data = test_csv.drop(['id'], axis = 1)\n\n# impute x_train and test\nimputer.fit(X_train)\nX_train = imputer.transform(X_train)\ntest_data = imputer.transform(test_data)\n\n# scale data\nscaler.fit(X_train)\nX_scaled = scaler.transform(X_train)\ntest_data_scaled = scaler.transform(test_data)\n\n# split into train and valdation\nX_train, X_val, y_train, y_val = train_test_split(X_scaled,y_train_val,test_size=0.2, stratify=y_train_val, random_state=my_ID)\n\n# Check\nprint(X_train.shape, X_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-30T02:20:53.229990Z","iopub.execute_input":"2022-10-30T02:20:53.230405Z","iopub.status.idle":"2022-10-30T02:21:06.577715Z","shell.execute_reply.started":"2022-10-30T02:20:53.230369Z","shell.execute_reply":"2022-10-30T02:21:06.576381Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(655542, 65) (163886, 65)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Logistic Regression - after testing a few combinations I found 'l2 saga 1' to give the highest accuracy","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\nfrom sklearn.linear_model import LogisticRegression\n\nsolver_penalty = [['saga', 'l2'], ['saga', 'l1']]\n# c_list = [0.2, 0.4, 0.6, 0.8, 1]\nc_list = [0.5,1]\n\ndef logistic_regression(P, S, c, X_train, y_train, X_val, y_val):\n    lr = LogisticRegression(penalty = P, solver = S, C=c, max_iter=1000)\n    lr.fit(X_train, y_train)\n    predictions = lr.predict(X_val)\n    accuracy = accuracy_score(y_val, predictions)\n    print(\"Accuracy \" + str(accuracy) + \" \" + str(P) + \" \" + str(S) + \" \" + str(c))\n\n'''    \nfor s, p in solver_penalty:\n    for c in c_list:\n        logistic_regression(p, s, c, X_train, y_train, X_val, y_val)\n'''\n        \nlogistic_regression('l2', 'saga', 1, X_train, y_train, X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-10-30T02:21:12.432851Z","iopub.execute_input":"2022-10-30T02:21:12.433244Z","iopub.status.idle":"2022-10-30T02:44:47.116451Z","shell.execute_reply.started":"2022-10-30T02:21:12.433213Z","shell.execute_reply":"2022-10-30T02:44:47.115028Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Accuracy 0.8137241741210354 l2 saga 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Decision Trees - after testing a few combinations I found 'entropy best 420' to give the highest accuracy","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\nfrom sklearn.tree import DecisionTreeClassifier \n\ncriterion_list = ['gini','entropy'] # omit log_loss due to key error\nsplitter_list = ['best','random']\nmin_sample = [400, 410, 420, 425] # 2 is default, try 3 4 5, 4 6 8 10 12 14 16 18 20\n\ndef decision_tree(c, s, m, X_train, y_train, X_val, y_val):\n    clf = DecisionTreeClassifier(random_state=my_ID, criterion = c, splitter = s, min_samples_split = m)\n    clf.fit(X_train, y_train)\n    predictions = clf.predict(X_val)\n    accuracy = accuracy_score(y_val, predictions)\n    print(\"Accuracy \" + str(accuracy) + \" \" + str(c) + \" \" + str(s) + \" \" + str(m))\n\n'''\nfor c in criterion_list:\n    for s in splitter_list:\n        for m in min_sample:\n            decision_tree(c, s, m, X_train, y_train, X_val, y_val)\n'''\n            \ndecision_tree('entropy', 'best', 420, X_train, y_train, X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-10-30T03:00:52.183475Z","iopub.execute_input":"2022-10-30T03:00:52.183934Z","iopub.status.idle":"2022-10-30T03:01:04.369912Z","shell.execute_reply.started":"2022-10-30T03:00:52.183901Z","shell.execute_reply":"2022-10-30T03:01:04.368590Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Accuracy 0.825506754695337 entropy best 420\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ensemble Classifier - XGBoost, this was one of the best results that I get with the train and validation split in the data","metadata":{}},{"cell_type":"code","source":"# randomforrest vs xgboost vs adaboost, xgboost is parallel so use this?\nfrom sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\nimport xgboost as xgb\n\nxgb_model = xgb.XGBClassifier(objective='multi:softmax', random_state=my_ID, num_class=5, tree_method = 'hist',n_estimators=147) #'gpu_hist')\nxgb_model.fit(X_train, y_train)\npredictions = xgb_model.predict(X_val)\n\naccuracy = accuracy_score(y_val, predictions)\nprint(\"Accuracy \" + str(accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-10-29T22:50:22.596320Z","iopub.execute_input":"2022-10-29T22:50:22.597399Z","iopub.status.idle":"2022-10-29T22:52:20.984681Z","shell.execute_reply.started":"2022-10-29T22:50:22.597338Z","shell.execute_reply":"2022-10-29T22:52:20.982958Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Accuracy 0.8391564868262085\n","output_type":"stream"}]},{"cell_type":"code","source":"# built in cross validation, want high boost but not too high\nparam = {'max_depth':2, 'eta':1, 'objective':'multi:softmax', 'num_class':5}\ndtrain = xgb.DMatrix(X_scaled, y_train_val)\nres = xgb.cv(param, dtrain, num_boost_round=150, nfold=5, metrics={'merror'}, seed=my_ID)\nprint(res)                        \n\n# look at 1st and 3rd columns\n# train acc go down but test going up - is the point where we choose number of boost rounds\n# smallest in test error mean, same index in train is accuracy\n\ndf = pd.DataFrame(res)\nindex = df['test-merror-mean'].idxmin()\nrow = df.iloc[[index]]\nprint(\"Accuracy \" + str(1 - row.iloc[:,0]))","metadata":{"execution":{"iopub.status.busy":"2022-10-29T22:52:28.681752Z","iopub.execute_input":"2022-10-29T22:52:28.682198Z","iopub.status.idle":"2022-10-29T23:15:37.635261Z","shell.execute_reply.started":"2022-10-29T22:52:28.682164Z","shell.execute_reply":"2022-10-29T23:15:37.633950Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"     train-merror-mean  train-merror-std  test-merror-mean  test-merror-std\n0             0.245280          0.000222          0.245297         0.000643\n1             0.211005          0.000399          0.211000         0.000275\n2             0.209397          0.000216          0.209436         0.000704\n3             0.203084          0.000717          0.203172         0.000830\n4             0.195060          0.000726          0.195305         0.000678\n..                 ...               ...               ...              ...\n145           0.161251          0.000110          0.162671         0.000226\n146           0.161237          0.000099          0.162662         0.000227\n147           0.161222          0.000100          0.162710         0.000231\n148           0.161187          0.000100          0.162685         0.000245\n149           0.161164          0.000120          0.162624         0.000190\n\n[150 rows x 4 columns]\nAccuracy 149    0.838836\nName: train-merror-mean, dtype: float64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Neural Network - I found fewer but wider layers gave better results","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nimport tensorflow as tf\nfrom tensorflow import keras\n\nmodel = Sequential()\nmodel.add(keras.layers.Dense(700, activation=\"relu\")) # also potentially add dropout layers between dense layers\nmodel.add(keras.layers.Dense(700, activation=\"relu\")) \nmodel.add(keras.layers.Dense(5, activation=\"softmax\")) # try widening layers and potentially making it deeper? more epochs?\n\n# learning rate\nopt=keras.optimizers.Adam(learning_rate=0.0003)\n\n# compile\nmodel.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# fit\nhistory = model.fit(X_train, np.array(y_train), validation_data=(X_val,np.array(y_val)), batch_size=65526, epochs=100) # experiment with epochs value\n\nprint(\"Accuracy \" + str(history.history['val_accuracy'][-1]))\n\nimport matplotlib.pyplot as plt\npd.DataFrame(history.history).plot(figsize=(8,5))\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-30T03:04:55.183726Z","iopub.execute_input":"2022-10-30T03:04:55.184687Z","iopub.status.idle":"2022-10-30T03:37:32.489566Z","shell.execute_reply.started":"2022-10-30T03:04:55.184621Z","shell.execute_reply":"2022-10-30T03:37:32.488131Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-10-30 03:05:01.492014: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n2022-10-30 03:05:02.346203: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n11/11 [==============================] - 21s 2s/step - loss: 1.0523 - accuracy: 0.5630 - val_loss: 0.7169 - val_accuracy: 0.6957\nEpoch 2/100\n11/11 [==============================] - 19s 2s/step - loss: 0.6633 - accuracy: 0.7309 - val_loss: 0.5978 - val_accuracy: 0.7568\nEpoch 3/100\n11/11 [==============================] - 20s 2s/step - loss: 0.5676 - accuracy: 0.7704 - val_loss: 0.5342 - val_accuracy: 0.7860\nEpoch 4/100\n11/11 [==============================] - 20s 2s/step - loss: 0.5178 - accuracy: 0.7909 - val_loss: 0.4989 - val_accuracy: 0.7948\nEpoch 5/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4888 - accuracy: 0.7991 - val_loss: 0.4762 - val_accuracy: 0.8010\nEpoch 6/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4702 - accuracy: 0.8041 - val_loss: 0.4628 - val_accuracy: 0.8072\nEpoch 7/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4580 - accuracy: 0.8094 - val_loss: 0.4534 - val_accuracy: 0.8100\nEpoch 8/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4494 - accuracy: 0.8120 - val_loss: 0.4454 - val_accuracy: 0.8125\nEpoch 9/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4431 - accuracy: 0.8133 - val_loss: 0.4404 - val_accuracy: 0.8131\nEpoch 10/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4382 - accuracy: 0.8148 - val_loss: 0.4362 - val_accuracy: 0.8148\nEpoch 11/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4342 - accuracy: 0.8165 - val_loss: 0.4338 - val_accuracy: 0.8156\nEpoch 12/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4314 - accuracy: 0.8176 - val_loss: 0.4332 - val_accuracy: 0.8152\nEpoch 13/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4305 - accuracy: 0.8175 - val_loss: 0.4305 - val_accuracy: 0.8159\nEpoch 14/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4277 - accuracy: 0.8189 - val_loss: 0.4277 - val_accuracy: 0.8173\nEpoch 15/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4251 - accuracy: 0.8199 - val_loss: 0.4259 - val_accuracy: 0.8177\nEpoch 16/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4238 - accuracy: 0.8203 - val_loss: 0.4252 - val_accuracy: 0.8177\nEpoch 17/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4227 - accuracy: 0.8202 - val_loss: 0.4251 - val_accuracy: 0.8184\nEpoch 18/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4212 - accuracy: 0.8207 - val_loss: 0.4229 - val_accuracy: 0.8188\nEpoch 19/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4197 - accuracy: 0.8215 - val_loss: 0.4213 - val_accuracy: 0.8205\nEpoch 20/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4185 - accuracy: 0.8218 - val_loss: 0.4204 - val_accuracy: 0.8199\nEpoch 21/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4175 - accuracy: 0.8221 - val_loss: 0.4197 - val_accuracy: 0.8209\nEpoch 22/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4170 - accuracy: 0.8223 - val_loss: 0.4188 - val_accuracy: 0.8213\nEpoch 23/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4163 - accuracy: 0.8220 - val_loss: 0.4189 - val_accuracy: 0.8213\nEpoch 24/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4153 - accuracy: 0.8227 - val_loss: 0.4180 - val_accuracy: 0.8213\nEpoch 25/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4150 - accuracy: 0.8228 - val_loss: 0.4169 - val_accuracy: 0.8222\nEpoch 26/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4139 - accuracy: 0.8235 - val_loss: 0.4200 - val_accuracy: 0.8193\nEpoch 27/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4144 - accuracy: 0.8229 - val_loss: 0.4167 - val_accuracy: 0.8226\nEpoch 28/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4137 - accuracy: 0.8233 - val_loss: 0.4165 - val_accuracy: 0.8218\nEpoch 29/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4129 - accuracy: 0.8238 - val_loss: 0.4166 - val_accuracy: 0.8219\nEpoch 30/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4123 - accuracy: 0.8238 - val_loss: 0.4157 - val_accuracy: 0.8226\nEpoch 31/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4109 - accuracy: 0.8245 - val_loss: 0.4143 - val_accuracy: 0.8228\nEpoch 32/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4107 - accuracy: 0.8247 - val_loss: 0.4152 - val_accuracy: 0.8223\nEpoch 33/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4104 - accuracy: 0.8246 - val_loss: 0.4157 - val_accuracy: 0.8217\nEpoch 34/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4116 - accuracy: 0.8232 - val_loss: 0.4180 - val_accuracy: 0.8199\nEpoch 35/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4109 - accuracy: 0.8245 - val_loss: 0.4140 - val_accuracy: 0.8227\nEpoch 36/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4089 - accuracy: 0.8252 - val_loss: 0.4129 - val_accuracy: 0.8236\nEpoch 37/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4081 - accuracy: 0.8255 - val_loss: 0.4130 - val_accuracy: 0.8237\nEpoch 38/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4089 - accuracy: 0.8257 - val_loss: 0.4128 - val_accuracy: 0.8237\nEpoch 39/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4076 - accuracy: 0.8257 - val_loss: 0.4125 - val_accuracy: 0.8235\nEpoch 40/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4076 - accuracy: 0.8258 - val_loss: 0.4126 - val_accuracy: 0.8237\nEpoch 41/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4068 - accuracy: 0.8263 - val_loss: 0.4144 - val_accuracy: 0.8219\nEpoch 42/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4082 - accuracy: 0.8251 - val_loss: 0.4137 - val_accuracy: 0.8225\nEpoch 43/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4070 - accuracy: 0.8257 - val_loss: 0.4123 - val_accuracy: 0.8236\nEpoch 44/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4064 - accuracy: 0.8260 - val_loss: 0.4122 - val_accuracy: 0.8239\nEpoch 45/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4056 - accuracy: 0.8264 - val_loss: 0.4102 - val_accuracy: 0.8244\nEpoch 46/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4049 - accuracy: 0.8268 - val_loss: 0.4105 - val_accuracy: 0.8244\nEpoch 47/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4051 - accuracy: 0.8266 - val_loss: 0.4108 - val_accuracy: 0.8239\nEpoch 48/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4045 - accuracy: 0.8269 - val_loss: 0.4102 - val_accuracy: 0.8245\nEpoch 49/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4052 - accuracy: 0.8261 - val_loss: 0.4111 - val_accuracy: 0.8234\nEpoch 50/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4048 - accuracy: 0.8262 - val_loss: 0.4101 - val_accuracy: 0.8246\nEpoch 51/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4035 - accuracy: 0.8271 - val_loss: 0.4094 - val_accuracy: 0.8242\nEpoch 52/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4039 - accuracy: 0.8267 - val_loss: 0.4096 - val_accuracy: 0.8248\nEpoch 53/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4033 - accuracy: 0.8273 - val_loss: 0.4096 - val_accuracy: 0.8248\nEpoch 54/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4036 - accuracy: 0.8268 - val_loss: 0.4086 - val_accuracy: 0.8251\nEpoch 55/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4025 - accuracy: 0.8276 - val_loss: 0.4083 - val_accuracy: 0.8252\nEpoch 56/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4018 - accuracy: 0.8278 - val_loss: 0.4077 - val_accuracy: 0.8251\nEpoch 57/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4016 - accuracy: 0.8281 - val_loss: 0.4088 - val_accuracy: 0.8246\nEpoch 58/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4032 - accuracy: 0.8271 - val_loss: 0.4085 - val_accuracy: 0.8253\nEpoch 59/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4024 - accuracy: 0.8274 - val_loss: 0.4094 - val_accuracy: 0.8249\nEpoch 60/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4020 - accuracy: 0.8279 - val_loss: 0.4074 - val_accuracy: 0.8258\nEpoch 61/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.4086 - val_accuracy: 0.8245\nEpoch 62/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4024 - accuracy: 0.8273 - val_loss: 0.4075 - val_accuracy: 0.8254\nEpoch 63/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4007 - accuracy: 0.8285 - val_loss: 0.4082 - val_accuracy: 0.8248\nEpoch 64/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4007 - accuracy: 0.8285 - val_loss: 0.4074 - val_accuracy: 0.8254\nEpoch 65/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4004 - accuracy: 0.8286 - val_loss: 0.4083 - val_accuracy: 0.8243\nEpoch 66/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4016 - accuracy: 0.8277 - val_loss: 0.4063 - val_accuracy: 0.8256\nEpoch 67/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4002 - accuracy: 0.8285 - val_loss: 0.4077 - val_accuracy: 0.8248\nEpoch 68/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4002 - accuracy: 0.8286 - val_loss: 0.4074 - val_accuracy: 0.8250\nEpoch 69/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3998 - accuracy: 0.8285 - val_loss: 0.4080 - val_accuracy: 0.8247\nEpoch 70/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4007 - accuracy: 0.8284 - val_loss: 0.4071 - val_accuracy: 0.8247\nEpoch 71/100\n11/11 [==============================] - 19s 2s/step - loss: 0.4000 - accuracy: 0.8282 - val_loss: 0.4073 - val_accuracy: 0.8251\nEpoch 72/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3988 - accuracy: 0.8291 - val_loss: 0.4056 - val_accuracy: 0.8257\nEpoch 73/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3982 - accuracy: 0.8296 - val_loss: 0.4063 - val_accuracy: 0.8257\nEpoch 74/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3992 - accuracy: 0.8288 - val_loss: 0.4087 - val_accuracy: 0.8247\nEpoch 75/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3996 - accuracy: 0.8284 - val_loss: 0.4075 - val_accuracy: 0.8245\nEpoch 76/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3994 - accuracy: 0.8282 - val_loss: 0.4059 - val_accuracy: 0.8255\nEpoch 77/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3983 - accuracy: 0.8291 - val_loss: 0.4083 - val_accuracy: 0.8243\nEpoch 78/100\n11/11 [==============================] - 20s 2s/step - loss: 0.4009 - accuracy: 0.8275 - val_loss: 0.4078 - val_accuracy: 0.8246\nEpoch 79/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3988 - accuracy: 0.8291 - val_loss: 0.4059 - val_accuracy: 0.8255\nEpoch 80/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3979 - accuracy: 0.8292 - val_loss: 0.4048 - val_accuracy: 0.8262\nEpoch 81/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3982 - accuracy: 0.8291 - val_loss: 0.4048 - val_accuracy: 0.8261\nEpoch 82/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3969 - accuracy: 0.8301 - val_loss: 0.4040 - val_accuracy: 0.8260\nEpoch 83/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3959 - accuracy: 0.8305 - val_loss: 0.4046 - val_accuracy: 0.8264\nEpoch 84/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3968 - accuracy: 0.8299 - val_loss: 0.4046 - val_accuracy: 0.8258\nEpoch 85/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3969 - accuracy: 0.8297 - val_loss: 0.4056 - val_accuracy: 0.8254\nEpoch 86/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3978 - accuracy: 0.8291 - val_loss: 0.4046 - val_accuracy: 0.8259\nEpoch 87/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3961 - accuracy: 0.8303 - val_loss: 0.4050 - val_accuracy: 0.8258\nEpoch 88/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3967 - accuracy: 0.8299 - val_loss: 0.4039 - val_accuracy: 0.8268\nEpoch 89/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3967 - accuracy: 0.8299 - val_loss: 0.4051 - val_accuracy: 0.8261\nEpoch 90/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3965 - accuracy: 0.8301 - val_loss: 0.4038 - val_accuracy: 0.8263\nEpoch 91/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3955 - accuracy: 0.8306 - val_loss: 0.4040 - val_accuracy: 0.8268\nEpoch 92/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3958 - accuracy: 0.8304 - val_loss: 0.4054 - val_accuracy: 0.8265\nEpoch 93/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3963 - accuracy: 0.8300 - val_loss: 0.4034 - val_accuracy: 0.8264\nEpoch 94/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3952 - accuracy: 0.8304 - val_loss: 0.4037 - val_accuracy: 0.8263\nEpoch 95/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3949 - accuracy: 0.8305 - val_loss: 0.4034 - val_accuracy: 0.8262\nEpoch 96/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3948 - accuracy: 0.8307 - val_loss: 0.4036 - val_accuracy: 0.8265\nEpoch 97/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3942 - accuracy: 0.8310 - val_loss: 0.4035 - val_accuracy: 0.8268\nEpoch 98/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3944 - accuracy: 0.8307 - val_loss: 0.4043 - val_accuracy: 0.8257\nEpoch 99/100\n11/11 [==============================] - 20s 2s/step - loss: 0.3953 - accuracy: 0.8298 - val_loss: 0.4081 - val_accuracy: 0.8231\nEpoch 100/100\n11/11 [==============================] - 19s 2s/step - loss: 0.3963 - accuracy: 0.8295 - val_loss: 0.4037 - val_accuracy: 0.8260\nAccuracy 0.826031506061554\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 576x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"The modified XGBoost code that gave me the best accuracy in the Kaggle competition, don't worry about the prediction accuracy because this is incorrect due to the validation data also being in the training data set. This was due to the idea of: train more data -> get better test score ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\nimport xgboost as xgb\n\nxgb_model = xgb.XGBClassifier(objective='multi:softmax', random_state=my_ID, num_class=5, tree_method = 'hist',n_estimators=478, max_depth=4) #'gpu_hist')\nxgb_model.fit(X_scaled, y_train_val)\npredictions = xgb_model.predict(X_val)\n\naccuracy = accuracy_score(y_val, predictions)\nprint(\"Accuracy \" + str(accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-10-28T05:39:36.790562Z","iopub.execute_input":"2022-10-28T05:39:36.790993Z","iopub.status.idle":"2022-10-28T05:45:37.475157Z","shell.execute_reply.started":"2022-10-28T05:39:36.790948Z","shell.execute_reply":"2022-10-28T05:45:37.473866Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Accuracy 0.8479430823865369\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Code to predict on the test data and output a csv for the competition","metadata":{}},{"cell_type":"code","source":"# submission\nout = xgb_model.predict(test_data_scaled) # xgbboost\n# out = model.predict(test_data_scaled) #neural network\n\nimport os\nos.chdir(r'/kaggle/working')\n\ndata={ 'id': test_csv.id.values, 'target':out}\nout = pd.DataFrame(data=data)\nout = out.replace(0,'c0')\nout = out.replace(1,'c1')\nout = out.replace(2,'c2')\nout = out.replace(3,'c3')\nout = out.replace(4,'c4')\n\nout.to_csv(r'output.csv', index=False)\n\nfrom IPython.display import FileLink\nFileLink(r'output.csv')\n\n#pca transform","metadata":{"execution":{"iopub.status.busy":"2022-10-28T05:49:13.677438Z","iopub.execute_input":"2022-10-28T05:49:13.677929Z","iopub.status.idle":"2022-10-28T05:49:46.820772Z","shell.execute_reply.started":"2022-10-28T05:49:13.677894Z","shell.execute_reply":"2022-10-28T05:49:46.818818Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/output.csv","text/html":"<a href='output.csv' target='_blank'>output.csv</a><br>"},"metadata":{}}]}]}